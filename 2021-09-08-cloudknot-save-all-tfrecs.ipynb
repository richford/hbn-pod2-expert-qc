{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudknot as ck\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = [\"b0-tensorfa-dwiqc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecs(s3_input_dir):\n",
    "    import nobrainer\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import os.path as op\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    from glob import glob\n",
    "    from s3fs import S3FileSystem\n",
    "\n",
    "    # Download the QC scores from S3 FCP-INDI\n",
    "    df_qc = pd.read_csv(\n",
    "        \"s3://fcp-indi/data/Projects/HBN/BIDS_curated/derivatives/qsiprep/participants.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index_col=\"subject_id\"\n",
    "    )\n",
    "\n",
    "    # Download nifti files from S3 to local\n",
    "    local_nifti_dir = \"niftis\"\n",
    "    local_tfrec_dir = \"tfrecs\"\n",
    "    os.makedirs(local_nifti_dir, exist_ok=True)\n",
    "    os.makedirs(local_tfrec_dir, exist_ok=True)\n",
    "        \n",
    "    fs = S3FileSystem()\n",
    "    fs.get(f\"hbn-pod2-deep-learning/{s3_input_dir}\", local_nifti_dir, recursive=True)\n",
    "\n",
    "    nifti_files = [op.abspath(filename) for filename in glob(f\"{local_nifti_dir}/*.nii.gz\")]\n",
    "    nifti_files = [fn for fn in nifti_files if \"irregularsize\" not in fn]\n",
    "    sub_id_pattern = re.compile(\"sub-[a-zA-Z0-9]*\")\n",
    "    subjects = [sub_id_pattern.search(s).group(0) for s in nifti_files]\n",
    "    \n",
    "    df_nifti = pd.DataFrame(data=nifti_files, index=subjects, columns=[\"features\"])\n",
    "    df_nifti = df_nifti.merge(df_qc, left_index=True, right_index=True, how=\"left\")\n",
    "    df_nifti.drop(\"scan_site_id\", axis=\"columns\", inplace=True)\n",
    "    df_nifti.rename(columns={\"fibr + qsiprep rating\": \"labels\"}, inplace=True)\n",
    "\n",
    "    filepaths = list(df_nifti.itertuples(index=False, name=None))\n",
    "    \n",
    "    n_channels = {\n",
    "        \"b0-colorfa-rgb\": 3,\n",
    "        \"combined\": 4,\n",
    "        \"b0-tensorfa-dwiqc\": 5,\n",
    "    }\n",
    "    \n",
    "    # Verify that all volumes have the same shape\n",
    "    invalid = nobrainer.io.verify_features_labels(\n",
    "        filepaths, volume_shape=(128, 128, 128, n_channels[s3_input_dir]),\n",
    "        check_labels_int=False,\n",
    "        check_labels_gte_zero=False,\n",
    "    )\n",
    "    print(\"Invalid:\", invalid)\n",
    "    assert not invalid    \n",
    "    \n",
    "    os.makedirs(local_tfrec_dir, exist_ok=True)\n",
    "\n",
    "    nobrainer.tfrecord.write(\n",
    "        features_labels=filepaths,\n",
    "        filename_template=local_tfrec_dir + \"/data-all_shard-{shard:03d}.tfrec\",\n",
    "        examples_per_shard=20\n",
    "    )\n",
    "    \n",
    "    output_s3_dirs = {\n",
    "        \"b0-colorfa-rgb\": \"tfrecs/b0-colorfa-rgb-nosplit\",\n",
    "        \"combined\": \"tfrecs/b0-colorfa-4channel-nosplit\",\n",
    "        \"b0-tensorfa-dwiqc\": \"tfrecs/b0-tensorfa-dwiqc-nosplit\"\n",
    "    }\n",
    "    \n",
    "    df_nifti.to_csv(op.join(local_tfrec_dir, \"filepaths.csv\"))\n",
    "\n",
    "    fs = S3FileSystem()\n",
    "    fs.put(\n",
    "        local_tfrec_dir,\n",
    "        f\"hbn-pod2-deep-learning/{output_s3_dirs[s3_input_dir]}\",\n",
    "        recursive=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cloudknot.dockerimage:Warning, some imports not found by pipreqs. You will need to edit the Dockerfile by hand, e.g by installing from github. You need to install the following packages []\n"
     ]
    }
   ],
   "source": [
    "di = ck.DockerImage(\n",
    "    func=create_tfrecs,\n",
    "    base_image=\"python:3.8\",\n",
    "    github_installs=\"https://github.com/richford/nobrainer.git@enh/four-d\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.build(tags=[\"hbn-pod2-tfrecs-20210908\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = ck.aws.DockerRepo(name=ck.get_ecr_repo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The very first time you run this, this command could take a few minutes\n",
    "di.push(repo=repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify bid_percentage to use Spot instances\n",
    "# And make sure the volume size is large enough. 55-60 GB seems about right for HBN preprocessing. YMMV.\n",
    "knot = ck.Knot(\n",
    "    name=\"hbn-pod2-tfrecs-20210917-0\",\n",
    "    docker_image=di,\n",
    "    pars_policies=(\"AmazonS3FullAccess\",),\n",
    "    bid_percentage=100,\n",
    "    memory=8000,\n",
    "    job_def_vcpus=8,\n",
    "    volume_size=100,\n",
    "    max_vcpus=64,\n",
    "    retries=1,\n",
    "    aws_resource_tags={\"Project\": \"HBN-FCP-INDI\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = knot.map(input_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID              Name                        Status   \n",
      "---------------------------------------------------------\n",
      "d95f98ad-22a8-4d7e-8a7d-62003b860776        hbn-pod2-tfrecs-20210917-0-0        SUBMITTED\n"
     ]
    }
   ],
   "source": [
    "knot.view_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot.clobber(clobber_pars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
